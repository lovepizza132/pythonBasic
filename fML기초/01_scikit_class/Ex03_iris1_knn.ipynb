{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### * sklearn 라이브러리에서 간단한 분류 모델에 관련하여 SVM과 KNN 이 있다\n",
    "\n",
    " KNN (K-Nearest Neighbors) : 최근접 분류기\n",
    "\t새로운 데이터가 들어오면 훈련데이타 중에서 가장 가까운 데이터 K개를 찾는다.\n",
    "\t이 중에서 빈도가 높은 label(결과)을 새 데이터의 레이블로 예측한다. \n",
    "\t\t- fit() : 학습기계에 데이터를 학습시키는 메소드\n",
    "\t\t- predict() : 데이터를 넣고 예측하는 메소드\n",
    "\t\t- score() : 정확도 측정\n",
    "\n",
    "svm(서포트벡터머신:분류, 회귀) 알고리즘 : 분류(SVC), 회귀(SVR)\n",
    "\t\t- fit() : 학습기계에 데이터를 학습시키는 메소드\n",
    "\t\t- predict() : 데이터를 넣고 예측하는 메소드\n",
    "\t\t- metrics.accuracy_score() : 정확도 측정 (검증)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 절차\n",
    "\n",
    "(1) 데이타 읽어오기\n",
    "\n",
    "(2) 데이터와 레이블 분리 변수 선언\n",
    "\n",
    "(3) 훈련데이터와 테스트 데이터로 분리하기\n",
    "\n",
    "(4) 모델로 학습하기\n",
    "\n",
    "(5) 예측하기\n",
    "\n",
    "(6) 검증하기\n",
    "\n",
    "(7) 정확도 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 데이타 읽어오기\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) 데이터와 레이블 분리 변수 선언 ( 이미 데이터와 레이블이 정해짐 )\n",
    "X=iris['data']\n",
    "y=iris['target'] # 답(레이블)이라고 부름\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1 3.  4.6 1.4]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.4 3.9 1.3 0.4]]\n",
      "[[5.6 2.8 4.9 2. ]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.3 2.7 4.9 1.8]]\n",
      "[1 2 1 2 1 2 2 1 2 0]\n",
      "[2 1 0 0 2 2 0 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# (3) 훈련데이터와 테스트 데이터로 분리하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.7) # 기본값 학습데이타8: 검증데이타2\n",
    "X_train # head()는 df에서만 사용 가능\n",
    "\n",
    "\n",
    "print(X_train[:10]) # 훈련데이터(학습할 데이터)\n",
    "print(X_test[:10])  # 검증데이터\n",
    "print(y_train[:10]) # 훈련답(학습에 대한 답)\n",
    "print(y_test[:10])  # 검증데이타의 답\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (4) 모델에 데이터를 학습하기\n",
    "# 훈련데이타와 훈련레이블를 인자로 넣어 학습한 결과 knn 객체를 리턴한다\n",
    "# n_neighbors : 이웃갯수 지정\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train) # 지도학습(답과 학습을 같이 줌)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (5) 새로운 샘플 데이타가 들어왔을 때 label 예측하기\n",
    "# 너무 동떨어진 데이타 입력하면 결과 예측 성능이 낮기에 기존 샘플과 유사하게 만듬\n",
    "newData = np.array([[8.5, 5.5, 5., 0.3]]) \n",
    "\n",
    "prediction = knn.predict(newData)\n",
    "prediction # array([0]) = setosa\n",
    "iris['target_names'][prediction]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (6) 검증하기\n",
    "# 실제 레이블과 예측값의 정확도 확인\n",
    "\n",
    "knn.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (7) 정확도 측정 : mean() 함수 이용\n",
    "\n",
    "\"\"\"\n",
    "a = np.array([1,2,3,4])\n",
    "b = np.array([1,2,3,5])\n",
    "print(a==b)\n",
    "print(np.mean(a==b)) # True=1, False=0 의 평균\n",
    "\"\"\"\n",
    "# X_tets: 전체 데이타 중에서 검증하기 위해 검증하기 위해서 20% 데이타\n",
    "# y_test: 20% 검증데이타의 답\n",
    "\n",
    "y_predict = knn.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "ac_score = metrics.accuracy_score(y_test, y_predict)\n",
    "ac_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
